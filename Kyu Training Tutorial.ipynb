{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb173248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam, SGD,RMSprop\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62384345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd95ed0c",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **kyu_train.csv** file and split the games into a list.\n",
    "Every row of csv: `KL0000000001,B,B[pq],W[dd],B[dp],W[pd],B[jc],...`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. KL0000000001: Game ID\n",
    "    2. B: Player's color\n",
    "    3-... : Moves\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f8872fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./Training Dataset/kyu_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58532b01",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "496585f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92277370",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 4 dimensional feature map to represent the data as below:\n",
    " 1. Positions of black stones: mark them as 1 and the rest of the table as 0\n",
    " 2. Positions of white stones: mark them as 1 and the rest of the table as 0\n",
    " 3. Empty areas of the table: mark the empty areas as 1 and occupied areas as 0\n",
    " 4. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "Target value is a number between 0-361(19\\*19). Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0adb423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,10))\n",
    "    # x[:,:,6] = 1\n",
    "    map = []\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        map.append(row)\n",
    "        map.append(column)\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "            # x[:,:,6] = 0\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "            # x[:,:,6] = 0\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "\n",
    "        color = moves[-1][0]\n",
    "        if color == 'B':\n",
    "            x[last_move_row,last_move_column,4] = 1\n",
    "        else:\n",
    "            x[last_move_row,last_move_column,5] = 1\n",
    "\n",
    "        # #最後一子的周邊分布\n",
    "        # for dr, dc in [(last_move_row, last_move_column+1), (last_move_row, last_move_column-1), (last_move_row+1, last_move_column), (last_move_row-1, last_move_column)]:   \n",
    "        #     if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,0]:\n",
    "        #         x[dr,dc,9]=1\n",
    "        # #氣\n",
    "        # for dr, dc in [(last_move_row, last_move_column+1), (last_move_row, last_move_column-1), (last_move_row+1, last_move_column), (last_move_row-1, last_move_column)]:\n",
    "        #     if color == 'B':\n",
    "        #         if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,5]:\n",
    "        #             x[dr,dc,7]=1 \n",
    "        #     else:\n",
    "        #         if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,4]:\n",
    "        #             x[dr,dc,8]=1\n",
    "\n",
    "        \n",
    "    for i in range(0, len(map), 2):\n",
    "        qi = 4\n",
    "        for dr, dc in [(map[i], map[i+1]+1), (map[i], map[i+1]-1), (map[i]+1, map[i+1]), (map[i]-1, map[i+1])]:   \n",
    "            if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,0]:\n",
    "                qi-=1\n",
    "        if qi==1:\n",
    "            x[map[i],map[i+1],6]=1\n",
    "        if qi==2:\n",
    "            x[map[i],map[i+1],7]=1\n",
    "        if qi==3:\n",
    "            x[map[i],map[i+1],8]=1\n",
    "        if qi==4:\n",
    "            x[map[i],map[i+1],9]=1\n",
    "\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "758808ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 118500, Total Moves: 27135638\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46403360",
   "metadata": {},
   "source": [
    "The code below is run for baseline model only by using only the first 500 games from the dataset. You might need to create a data generator to use complete dataset. Otherwise your RAM might not enough to store all (If you run the code on free version of Google Colab, it will crash above 500 game samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9bb0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "# for game in games[:7000]:\n",
    "#     moves_list = game.split(',')\n",
    "#     for count, move in enumerate(moves_list):\n",
    "#         x.append(prepare_input(moves_list[:count]))\n",
    "#         y.append(prepare_label(moves_list[count]))\n",
    "# x = np.array(x)\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b2392a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73521b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5510a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_one_hot = tf.one_hot(y, depth=19*19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b048ff",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f594acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c5de9",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "208834da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     inputs = Input(shape=(19, 19, 4))\n",
    "#     outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "#     outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "#     outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "#     outputs = Flatten()(outputs)\n",
    "#     outputs = Softmax()(outputs)\n",
    "#     model = Model(inputs, outputs)\n",
    "    \n",
    "#     opt = Adam(learning_rate=0.001)\n",
    "#     model.compile(optimizer=opt,\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, Flatten, Dense, Softmax\n",
    "\n",
    "def residual_block(inputs, filters, kernel_size=3, strides=1):\n",
    "    shortcut = inputs\n",
    "\n",
    "    outputs = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "\n",
    "    outputs = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "    \n",
    "    outputs = Add()([outputs, shortcut])\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    return outputs\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 10))\n",
    "\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "\n",
    "    # Adding a residual block\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same')(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Softmax()(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    opt = opt = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a66e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 19, 19, 10)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 19, 19, 32)   15712       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 19, 19, 32)   50208       conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 19, 19, 32)   25632       conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 19, 19, 32)   25632       conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 19, 19, 32)   9248        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 19, 19, 32)   9248        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 19, 19, 32)   9248        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 19, 19, 32)   9248        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 19, 19, 32)   128         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 19, 19, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 19, 19, 32)   9248        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 19, 19, 32)   128         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 19, 19, 32)   0           batch_normalization_55[0][0]     \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 19, 19, 32)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 19, 19, 32)   9248        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 19, 19, 32)   128         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 19, 19, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 19, 19, 32)   9248        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 19, 19, 32)   128         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 19, 19, 32)   0           batch_normalization_57[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 19, 19, 32)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 19, 19, 32)   9248        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 19, 19, 32)   128         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 19, 19, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 19, 19, 32)   9248        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 19, 19, 32)   128         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 19, 19, 32)   0           batch_normalization_59[0][0]     \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 19, 19, 32)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 19, 19, 1)    289         activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 361)          0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, 361)          0           flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 201,473\n",
      "Trainable params: 201,089\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 17:28:18.101677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def games_generator():\n",
    "    for game in games:\n",
    "        yield from process_game(game)\n",
    "\n",
    "def process_game(game):\n",
    "    moves_list = game.split(',')\n",
    "    for count, move in enumerate(moves_list):\n",
    "        input_data = prepare_input(moves_list[:count])\n",
    "        label = prepare_label(moves_list[count])\n",
    "        yield input_data, label\n",
    "\n",
    "\n",
    "games_dataset = tf.data.Dataset.from_generator(\n",
    "    games_generator,\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=([19, 19, 10], [])\n",
    ")\n",
    "\n",
    "\n",
    "# 將數據集分成訓練和驗證集\n",
    "val_dataset = games_dataset.take(11000) \n",
    "train_dataset = games_dataset.skip(11000)\n",
    "\n",
    "# 對數據集進行批處理和預處理\n",
    "train_dataset = train_dataset.batch(512).map(lambda x, y: (x, tf.one_hot(y, depth=19*19)))\n",
    "val_dataset = val_dataset.batch(512).map(lambda x, y: (x, tf.one_hot(y, depth=19*19)))\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_path = \"test_model_bestkyu.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_loss',  # 監控準確度\n",
    "                             save_best_only=True,     # 只保存最佳模型\n",
    "                             mode='min',              # 目標是最大化監控指標\n",
    "                             verbose=1)\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=25,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=1000,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:05:52.875000: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 12450271968 exceeds 10% of free system memory.\n",
      "2023-11-21 11:05:56.274156: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-11-21 11:05:56.276709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2112000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:05:56.516477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-21 11:05:59.535158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-21 11:05:59.536415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2807/2807 [==============================] - 78s 26ms/step - loss: 4.2914 - accuracy: 0.1198 - val_loss: 3.2879 - val_accuracy: 0.3041\n",
      "Epoch 2/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 3.1513 - accuracy: 0.3232 - val_loss: 2.9832 - val_accuracy: 0.3496\n",
      "Epoch 3/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.9346 - accuracy: 0.3541 - val_loss: 2.9055 - val_accuracy: 0.3601\n",
      "Epoch 4/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.8232 - accuracy: 0.3692 - val_loss: 2.8380 - val_accuracy: 0.3691\n",
      "Epoch 5/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.7509 - accuracy: 0.3781 - val_loss: 2.7303 - val_accuracy: 0.3844\n",
      "Epoch 6/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.6928 - accuracy: 0.3866 - val_loss: 2.6953 - val_accuracy: 0.3902\n",
      "Epoch 7/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.6516 - accuracy: 0.3922 - val_loss: 2.6859 - val_accuracy: 0.3895\n",
      "Epoch 8/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.6194 - accuracy: 0.3968 - val_loss: 2.6682 - val_accuracy: 0.3920\n",
      "Epoch 9/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.5860 - accuracy: 0.4019 - val_loss: 2.5989 - val_accuracy: 0.4007\n",
      "Epoch 10/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.5574 - accuracy: 0.4057 - val_loss: 2.6063 - val_accuracy: 0.3993\n",
      "Epoch 11/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.5415 - accuracy: 0.4070 - val_loss: 2.5892 - val_accuracy: 0.4022\n",
      "Epoch 12/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.5196 - accuracy: 0.4101 - val_loss: 2.5623 - val_accuracy: 0.4065\n",
      "Epoch 13/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.5030 - accuracy: 0.4115 - val_loss: 2.5494 - val_accuracy: 0.4067\n",
      "Epoch 14/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4885 - accuracy: 0.4133 - val_loss: 2.5382 - val_accuracy: 0.4080\n",
      "Epoch 15/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4747 - accuracy: 0.4152 - val_loss: 2.5180 - val_accuracy: 0.4095\n",
      "Epoch 16/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4627 - accuracy: 0.4165 - val_loss: 2.5264 - val_accuracy: 0.4096\n",
      "Epoch 17/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4509 - accuracy: 0.4187 - val_loss: 2.5195 - val_accuracy: 0.4094\n",
      "Epoch 18/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4472 - accuracy: 0.4190 - val_loss: 2.5106 - val_accuracy: 0.4089\n",
      "Epoch 19/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4375 - accuracy: 0.4197 - val_loss: 2.5058 - val_accuracy: 0.4122\n",
      "Epoch 20/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4292 - accuracy: 0.4209 - val_loss: 2.4973 - val_accuracy: 0.4120\n",
      "Epoch 21/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4208 - accuracy: 0.4218 - val_loss: 2.5055 - val_accuracy: 0.4128\n",
      "Epoch 22/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4141 - accuracy: 0.4229 - val_loss: 2.4973 - val_accuracy: 0.4131\n",
      "Epoch 23/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4087 - accuracy: 0.4238 - val_loss: 2.4763 - val_accuracy: 0.4160\n",
      "Epoch 24/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.4042 - accuracy: 0.4238 - val_loss: 2.4852 - val_accuracy: 0.4144\n",
      "Epoch 25/25\n",
      "2807/2807 [==============================] - 73s 26ms/step - loss: 2.3997 - accuracy: 0.4247 - val_loss: 2.4902 - val_accuracy: 0.4150\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    batch_size = 512,\n",
    "    epochs = 25,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aaddf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_kyu_tutorial5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484be28d",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fafaa",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

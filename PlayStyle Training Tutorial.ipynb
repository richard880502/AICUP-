{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd5077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop,Adadelta\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d54d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666d92a",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **play_style_train.csv** file and split the games into a list.\n",
    "Every row of csv: `PSL0000000001,1,B[pd],W[dp],B[qp],W[dc],B[nq],W[nc],B[qf],W[kd],B[ce],W[dg],B[dd],W[cc],B[fd],W[ed],B[ee],W[ec],B[ge],W[gc],B[di]`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. PSL0000000001: Game ID\n",
    "    2. 1: Game Style\n",
    "    3-... : Moves, the last move represents the play style (B[di] in this case)\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4b559ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./Training Dataset/play_style_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "game_styles = [int(i.split(',',2)[-2]) for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f64af3",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b52349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3429687",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 2 dimensional feature map to represent the data as below:\n",
    " 1. Occupied areas: mark them as 1 and the empty places as 0\n",
    " 2. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "The target is to predict the game style (1, 2 or 3) from the state of the game table. Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b28ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,17))\n",
    "    map=[]\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        map.append(row)\n",
    "        map.append(column)\n",
    "        x[row,column,0] = 1\n",
    "        if color == 'B':\n",
    "            x[row,column,4] = 1\n",
    "        else:\n",
    "            x[row,column,5] = 1\n",
    "\n",
    "    for i in range(1,4):\n",
    "            if i>=len(moves):\n",
    "                break\n",
    "            lc = coordinates[moves[-1*i][2]]\n",
    "            lr = coordinates[moves[-1*i][3]]\n",
    "            x[lr,lc,i] = 1\n",
    "\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,1] = 1\n",
    "        \n",
    "\n",
    "        #最後一子的顏色\n",
    "        color = moves[-1][0]\n",
    "        if color == 'B':\n",
    "            x[last_move_row,last_move_column,15] = 1\n",
    "        else:\n",
    "            x[last_move_row,last_move_column,16] = 1\n",
    "        \n",
    "        #最後一子的周邊分布\n",
    "        for dr, dc in [(last_move_row, last_move_column+1), (last_move_row, last_move_column-1), (last_move_row+1, last_move_column), (last_move_row-1, last_move_column)]:   \n",
    "            if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,0]:\n",
    "                x[dr,dc,6]=1\n",
    "\n",
    "        #倒數第二子的氣\n",
    "        second_last_move_column = coordinates[moves[-1][2]]\n",
    "        second_last_move_row = coordinates[moves[-1][3]]\n",
    "        for dr, dc in [(second_last_move_row, second_last_move_column+1), (second_last_move_row, second_last_move_column-1), (second_last_move_row+1, second_last_move_column), (second_last_move_row-1, second_last_move_column),(second_last_move_row-1, second_last_move_column+1),(second_last_move_row-1, second_last_move_column-1),(second_last_move_row+1, second_last_move_column-1),(second_last_move_row+1, second_last_move_column+1)]:   \n",
    "            if color == 'B':\n",
    "                if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,5]:\n",
    "                    x[dr,dc,7]=1 \n",
    "            else:\n",
    "                if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,4]:\n",
    "                    x[dr,dc,8]=1 \n",
    "\n",
    "        #氣\n",
    "        for dr, dc in [(last_move_row, last_move_column+1), (last_move_row, last_move_column-1), (last_move_row+1, last_move_column), (last_move_row-1, last_move_column)]:\n",
    "            if color == 'B':\n",
    "                if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,5]:\n",
    "                    x[dr,dc,9]=1 \n",
    "            else:\n",
    "                if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,4]:\n",
    "                    x[dr,dc,10]=1\n",
    "\n",
    "             \n",
    "    for i in range(0, len(map), 2):\n",
    "        # if (map[i+1] == 0 and map[i]== 0) or (map[i+1] == 18 and map[i]== 18) or (map[i+1] == 0 and map[i]== 18) or (map[i+1] == 18 and map[i]== 0):\n",
    "        #     qi = 2\n",
    "        # elif map[i+1] == 0 or map[i+1] == 18 or map[i] == 0 or map[i] == 18:\n",
    "        #     qi = 3\n",
    "        # else:\n",
    "        qi = 4\n",
    "\n",
    "        for dr, dc in [(map[i], map[i+1]+1), (map[i], map[i+1]-1), (map[i]+1, map[i+1]), (map[i]-1, map[i+1])]:   \n",
    "            if 0 <= dr < 19 and 0<= dc < 19 and not x[dr,dc,0]:\n",
    "                qi-=1\n",
    "        if qi==1:\n",
    "            x[map[i],map[i+1],11]=1\n",
    "        if qi==2:\n",
    "            x[map[i],map[i+1],12]=1\n",
    "        if qi==3:\n",
    "            x[map[i],map[i+1],13]=1\n",
    "        if qi==4:\n",
    "            x[map[i],map[i+1],14]=1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1a544a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 26615\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30773a",
   "metadata": {},
   "source": [
    "Since play style training has smaller dataset comparing to kyu or dan training, we can put the complete dataset to memory. Still, it is better to create a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40cce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x.append(prepare_input(moves_list))\n",
    "x = np.array(x)\n",
    "y = np.array(game_styles)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74d9b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26615, 19, 19, 17)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ad8b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26615,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f20561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8184, 9403, 9028])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c86e70",
   "metadata": {},
   "source": [
    "Target is one-hot encoded and loss is changed to `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54f30621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 20:19:22.060395: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-11-27 20:19:22.060512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.060600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4060 Ti computeCapability: 8.9\n",
      "coreClock: 2.655GHz coreCount: 34 deviceMemorySize: 15.71GiB deviceMemoryBandwidth: 268.25GiB/s\n",
      "2023-11-27 20:19:22.060612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-27 20:19:22.060622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-27 20:19:22.060627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-27 20:19:22.060632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-27 20:19:22.060636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-27 20:19:22.060640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-11-27 20:19:22.060644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-27 20:19:22.060648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-27 20:19:22.060669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.060725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.060772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-11-27 20:19:22.060783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-27 20:19:22.226927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-27 20:19:22.226947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-11-27 20:19:22.226950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-11-27 20:19:22.227087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.227171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.227227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 20:19:22.227283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14858 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9)\n"
     ]
    }
   ],
   "source": [
    "y_hot = tf.one_hot(y, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae1a16",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b80a8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8964d8",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad6d4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, Flatten, Dense,Dropout,Attention\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed,Reshape\n",
    "def residual_block(inputs, filters, kernel_size=3, strides=1):\n",
    "    shortcut = inputs\n",
    "\n",
    "    outputs = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = Dropout(0.2)(outputs)\n",
    "\n",
    "    outputs = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "    \n",
    "    outputs = Add()([outputs, shortcut])\n",
    "    outputs = Activation('relu')(outputs)\n",
    "    outputs = Dropout(0.2)(outputs)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 17))\n",
    "\n",
    "    outputs = tf.keras.layers.ZeroPadding2D(padding=(10, 10))(inputs)\n",
    "    outputs = Conv2D(kernel_size=9, filters=32, strides=2, activation='relu')(outputs) \n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(outputs)\n",
    "\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "    outputs = residual_block(outputs, filters=32)\n",
    "    \n",
    "    # # RNN部分\n",
    "    # rnn_input = Reshape(target_shape=(17*17, 32))(outputs)  # 修改維度以符合RNN的要求\n",
    "    # outputs = LSTM(units=361, return_sequences=True)(rnn_input)  # 這裡使用LSTM作為示例\n",
    "\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(3, activation='softmax')(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    # opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
    "    opt = RMSprop(learning_rate=0.001, rho=0.5)\n",
    "    # opt = Adadelta(learning_rate=1.0, rho=0.9, epsilon=1e-07)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def transformer_block(inputs, num_heads=16, ff_dim=32, dropout_rate=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn_output = Dense(ff_dim, activation=\"relu\")(out1)\n",
    "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    return out2\n",
    "\n",
    "def create_transformer_model():\n",
    "    inputs = Input(shape=(19, 19, 15))\n",
    "\n",
    "    # Modify inputs if necessary for transformer\n",
    "    # Reshape or flatten inputs here as needed\n",
    "\n",
    "    # Transformer blocks\n",
    "    outputs = inputs\n",
    "    for _ in range(3):  # Three transformer blocks as in the previous model\n",
    "        outputs = transformer_block(outputs)\n",
    "\n",
    "    # Flatten or reshape outputs as needed for dense layers\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = Dense(3, activation='softmax')(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    opt = RMSprop(learning_rate=0.001, rho=0.5)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and compile the transformer model\n",
    "transformer_model = create_transformer_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "295280dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 19, 19, 17)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 39, 39, 17)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 32)   44096       zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 18, 18, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 18, 18, 32)   9248        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 18, 18, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 18, 18, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 18, 18, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 18, 18, 32)   9248        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 18, 18, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 18, 18, 32)   0           batch_normalization_2[0][0]      \n",
      "                                                                 zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 18, 18, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 18, 18, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 18, 18, 32)   9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 18, 18, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 18, 18, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 18, 18, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 18, 18, 32)   9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 18, 18, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 18, 18, 32)   0           batch_normalization_4[0][0]      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 18, 18, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 18, 18, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 18, 18, 32)   9248        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 18, 18, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 18, 18, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 18, 18, 32)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 18, 18, 32)   9248        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 18, 18, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 18, 18, 32)   0           batch_normalization_6[0][0]      \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 18, 18, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 18, 18, 32)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10368)        0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           331808      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32)           128         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32)           128         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           1056        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32)           128         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 3)            99          batch_normalization_9[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 434,883\n",
      "Trainable params: 434,243\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c826c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 20:19:27.831138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-11-27 20:19:27.831342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2112000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 20:19:28.547875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-27 20:19:28.813954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-27 20:19:28.817441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37/375 [=>............................] - ETA: 1s - loss: 1.3277 - accuracy: 0.3624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 20:19:29.557893: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 5ms/step - loss: 1.1024 - accuracy: 0.4506 - val_loss: 0.9558 - val_accuracy: 0.5353\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9175 - accuracy: 0.5687 - val_loss: 0.8846 - val_accuracy: 0.6003\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8770 - accuracy: 0.6000 - val_loss: 1.0224 - val_accuracy: 0.5601\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8198 - accuracy: 0.6418 - val_loss: 0.8397 - val_accuracy: 0.6322\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7595 - accuracy: 0.6756 - val_loss: 0.8322 - val_accuracy: 0.6401\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7329 - accuracy: 0.6879 - val_loss: 0.8686 - val_accuracy: 0.6225\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6895 - accuracy: 0.7113 - val_loss: 0.8189 - val_accuracy: 0.6510\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6492 - accuracy: 0.7321 - val_loss: 0.8724 - val_accuracy: 0.6255\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6254 - accuracy: 0.7461 - val_loss: 0.8321 - val_accuracy: 0.6600\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6020 - accuracy: 0.7550 - val_loss: 0.8266 - val_accuracy: 0.6476\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_path = \"model_playstyle6.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_loss',  # 監控準確度\n",
    "                             save_best_only=True,     # 只保存最佳模型\n",
    "                             mode='min',              # 目標是最大化監控指標\n",
    "                             verbose=1)\n",
    "history = model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data=(x_val, y_val),\n",
    "    # callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "model1 = load_model('./model_playstyle15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(x_val)\n",
    "\n",
    "# 假設你的標籤是 one-hot 編碼的，如果是整數編碼，請使用 accuracy_score(val_labels, predictions) 進行計算\n",
    "val_accuracy = accuracy_score(np.argmax(y_val, axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "print(f'Validation accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ed0f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_playstyle3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58388eb",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436139c",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
